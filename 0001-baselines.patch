From 7af3105a13a398576af4206168cbe45079161d8f Mon Sep 17 00:00:00 2001
From: trobr <trobr@xxx.com>
Date: Tue, 22 Oct 2024 15:09:17 +0800
Subject: [PATCH 1/3] =?UTF-8?q?baselines=E4=BF=AE=E6=94=B9?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .gitignore                                 | 10 ++++-
 requirements.txt                           | 21 +++++++----
 src/baselines/baselines/common/mpi_adam.py | 43 ++++++++++++++++++++++
 src/baselines/baselines/common/tf_util.py  |  3 +-
 src/baselines/baselines/her/normalizer.py  |  5 ++-
 5 files changed, 70 insertions(+), 12 deletions(-)

diff --git a/.gitignore b/.gitignore
index 641d773..22aacf5 100644
--- a/.gitignore
+++ b/.gitignore
@@ -5,4 +5,12 @@
 __pycache__
 gym-residual-fetch/gym_residual_fetch.egg-info
 assets/fetch_complex_objects
-venv/
\ No newline at end of file
+venv/
+
+
+/internal/
+/deps/
+**/*.DS_Store
+**/logs/
+**/logdir/
+**/*.egg-info
diff --git a/requirements.txt b/requirements.txt
index 254ee71..de500dd 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,8 +1,13 @@
--e git+https://github.com/openai/mujoco-py@a9f563cbb81d45f2379c6bcc4a4cd73fac09c4be#egg=mujoco_py
-numpy==1.14.5
-gym==0.10.9
-matplotlib==3.0.0
-pandas==0.23.4
-seaborn==0.9.0
--e git+https://github.com/openai/baselines.git@c28acb22030f594f94d128bf47b489cc704f593e#egg=baselines
-mpi4py==3.0.0
+# -e git+https://ghp.ci/https://github.com/openai/mujoco-py@a9f563cbb81d45f2379c6bcc4a4cd73fac09c4be#egg=mujoco_py
+# -e git+https://ghp.ci/https://github.com/openai/baselines.git@c28acb22030f594f94d128bf47b489cc704f593e#egg=baselines
+numpy==1.23.5
+gym==0.13.1
+matplotlib==3.9.2
+pandas==2.2.3
+seaborn==0.13.2
+mpi4py==4.0.1
+
+Cython<3
+# gymnasium
+# gymnasium-robotics
+tensorflow[and-cuda]==2.12.0
\ No newline at end of file
diff --git a/src/baselines/baselines/common/mpi_adam.py b/src/baselines/baselines/common/mpi_adam.py
index ccda451..0f867f5 100644
--- a/src/baselines/baselines/common/mpi_adam.py
+++ b/src/baselines/baselines/common/mpi_adam.py
@@ -4,6 +4,49 @@ try:
     from mpi4py import MPI
 except ImportError:
     MPI = None
+MPI = None
+
+
+import tensorflow as tf
+
+
+class TfAdamOptimizer(tf.compat.v1.train.Optimizer):
+    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name="MpiAdam"):
+        super(TfAdamOptimizer, self).__init__(use_locking, name)
+        self.learning_rate = learning_rate
+        self.beta1 = beta1
+        self.beta2 = beta2
+        self.epsilon = epsilon
+
+    def _create_slots(self, var_list):
+        for v in var_list:
+            self._zeros_slot(v, "m", self._name)
+            self._zeros_slot(v, "v", self._name)
+
+    def _apply_dense(self, grad, var):
+        m = self.get_slot(var, "m")
+        v = self.get_slot(var, "v")
+        
+        t = tf.compat.v1.train.get_or_create_global_step()
+        
+        t_plus_1 = tf.compat.v1.assign_add(t, 1)  # 直接更新 t
+        t_float = tf.cast(t_plus_1, tf.float32)
+        lr_t = self.learning_rate * tf.sqrt(1 - tf.pow(self.beta2, t_float)) / (1 - tf.pow(self.beta1, t_float))
+
+        m_t = m.assign(self.beta1 * m + (1 - self.beta1) * grad)
+        v_t = v.assign(self.beta2 * v + (1 - self.beta2) * tf.square(grad))
+
+        # 计算参数的更新
+        var_update = tf.compat.v1.assign_sub(var, lr_t * m_t / (tf.sqrt(v_t) + self.epsilon))
+
+        return tf.group(var_update, m_t, v_t, t_plus_1)
+
+    def _resource_apply_dense(self, grad, handle):
+        return self._apply_dense(grad, handle)
+
+    def _apply_sparse_shared(self, grad, var, indices, scatter_add):
+        raise NotImplementedError("Sparse gradient updates are not supported.")
+
 
 
 class MpiAdam(object):
diff --git a/src/baselines/baselines/common/tf_util.py b/src/baselines/baselines/common/tf_util.py
index db1076c..167b0c0 100644
--- a/src/baselines/baselines/common/tf_util.py
+++ b/src/baselines/baselines/common/tf_util.py
@@ -104,6 +104,7 @@ def flatgrad(grads, var_list, clip_norm=None):
         for (v, grad) in zip(var_list, grads)
     ])
 
+
 class SetFromFlat(object):
     def __init__(self, var_list, dtype=tf.float32):
         self.shapes = list(map(var_shape, var_list))
@@ -122,7 +123,7 @@ class GetFlat(object):
         self.var_list = var_list
 
     def __call__(self):
-        return tf.concat(axis=0, values=[tf.reshape(v, [numel(v)]) for v in self.var_list]).numpy()
+        return tf.concat(axis=0, values=[tf.reshape(v, [numel(v)]) for v in self.var_list])
 
 def flattenallbut0(x):
     return tf.reshape(x, [-1, intprod(x.get_shape().as_list()[1:])])
diff --git a/src/baselines/baselines/her/normalizer.py b/src/baselines/baselines/her/normalizer.py
index d02967c..1849192 100644
--- a/src/baselines/baselines/her/normalizer.py
+++ b/src/baselines/baselines/her/normalizer.py
@@ -2,13 +2,13 @@ import threading
 
 import numpy as np
 from mpi4py import MPI
-import tensorflow as tf
+import tensorflow.compat.v1 as tf
 
 from baselines.her.util import reshape_for_broadcasting
 
 
 class Normalizer(tf.Module):
-    def __init__(self, size, eps=1e-2, default_clip_range=np.inf):
+    def __init__(self, size, eps=1e-2, default_clip_range=np.inf, sess=None):
         """A normalizer that ensures that observations are approximately distributed according to
         a standard Normal distribution (i.e. have mean zero and variance one).
 
@@ -22,6 +22,7 @@ class Normalizer(tf.Module):
         self.size = size
         self.eps = eps
         self.default_clip_range = default_clip_range
+        self.sess = sess if sess is not None else tf.compat.v1.get_default_session()
 
         self.local_sum = np.zeros(self.size, np.float32)
         self.local_sumsq = np.zeros(self.size, np.float32)
-- 
2.39.3
